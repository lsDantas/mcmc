
# Processos Estocásticos
## Markov Chain Monte Carlo (MCMC)

**Grupo:** Atílio, Fredson, Giovani e Leonardo

Trabalho computacional para a disciplina de Processos Estocásticos. Este repositório contém os seguintes arquivos:

* `metropolis.py` - Implementação do algoritmo de Metropolis-Hastings.
* `exemplo_1.py` - Exemplo do algoritmo de Metropolis-Hastings aplicado a um problema onde a distribuição de proposta é uma cadeia de Markov finita.
* `exemplo_2.py` - Exemplo do algoritmo de Metropolis-Hastings aplicado a um problema onde a distribuição proposta é um passeio aleatório simétrico. Exercício busca aproximar uma lei de potência.
* `cadeia_finita.py` - Código auxiliar para encapsular dados de problemas envolvendo cadeias de Markov finitas.
* `passeio_aleatorio.py` - Código auxiliar para encapsular dados de problemas envolvendo passeios aleatórios simétricos.
* `mc_exemplo_1.py` - Código com exemplo de algoritmo que utiliza o método Monte Carlos para computar o valor de pi.
* `mc_exemplo_2.py` - Código com exemplo de algoritmo que utiliza o método de Monte Carlos para integrar funções.
* `KingMarkov.html` - Código da página web contém a ilustração de um algoritmo Metrópolis.
* `sketch.js` - Código javascript que gera a visualização animada da ilustração de um algoritmo Metrópolis.
* `gibbs.py` - Código que implementa o método de Amostragem de Gibbs
* `gibbs_exemplo1.py` - Implementa amostragem de uma distribuição uniforme bivariada [0,1]x[0,1]
* `gibbs_exemplo2.py` - Implementa amostragem de uma distribuição Normal Bivariada com forte fator de correlação.
* `gibbs_exemplo3.py` - Implementa amostragem dadas as marginais f(x|y) ~ Normal(0,1) e f(y|x) ~ Uniforme[x,x+1].
